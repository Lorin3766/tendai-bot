#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TendAI — LLM-only Professional Health & Longevity Assistant (RU/EN/ES/UA)

— No reply keyboards, no inline buttons.
— Immediate 40s intake after greeting (one message, user replies once).
— LLM-only: routing, triage, follow-ups, and final answers are generated by the model.
— ER escalation only on clear red flags with high confidence; otherwise ask targeted questions first.
— Compact, professional style (<=6 lines + short bullets).
— Commands: /start /reset /privacy /profile /plan /fast

Setup (env):
  TELEGRAM_TOKEN=...
  OPENAI_API_KEY=...
  OPENAI_MODEL=gpt-4o-mini   # optional
"""

import os
import re
import json
import logging
import time
from typing import Dict, Any, List, Optional
from collections import defaultdict, deque

from telegram import Update, ReplyKeyboardRemove
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
)

# ---------- OpenAI ----------
from openai import OpenAI

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "YOUR_TELEGRAM_TOKEN_HERE")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "YOUR_OPENAI_API_KEY_HERE")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

logging.basicConfig(
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
    level=logging.INFO
)
log = logging.getLogger("tendai-llm-only")

client = OpenAI(api_key=OPENAI_API_KEY)

# ---------- State ----------
class State:
    def __init__(self):
        self.lang: str = "en"
        self.intake_needed: bool = True
        self.profile: Dict[str, Any] = {}
        self.history: deque = deque(maxlen=14)  # [{role, content}]
        self.fast_mode: bool = False
        self.last_seen: float = time.time()

USERS: Dict[int, State] = defaultdict(State)

def now() -> float:
    return time.time()

# ---------- Language detection ----------
def detect_lang(update: Update, fallback="en") -> str:
    code = (update.effective_user.language_code or "").lower()
    text = (update.message.text or "").lower() if update.message else ""
    # priority: telegram code
    if code.startswith("ru"): return "ru"
    if code.startswith("uk"): return "uk"
    if code.startswith("es"): return "es"
    if code.startswith("en"): return "en"
    # quick lexical hints
    if any(w in text for w in ["привет", "здравствуйте", "самочувствие", "боль"]): return "ru"
    if any(w in text for w in ["привіт", "здоров'", "болить"]): return "uk"
    if any(w in text for w in ["hola", "salud", "dolor", "¿", "¡", "ñ"]): return "es"
    if any(w in text for w in ["hello","hi","pain","sleep","diet"]): return "en"
    return fallback

# ---------- Fixed minimal texts (only for greeting/privacy) ----------
TXT = {
    "greet": {
        "ru": "Привет, я TendAI — ассистент по здоровью и долголетию. Работаю кратко и по делу.",
        "en": "Hi, I’m TendAI — your health & longevity assistant. I’ll keep it short and useful.",
        "es": "Hola, soy TendAI — tu asistente de salud y longevidad. Iré al grano.",
        "uk": "Привіт, я TendAI — асистент зі здоров’я та довголіття. Коротко і по суті."
    },
    "privacy": {
        "ru": "Я не врач. Это не замена медпомощи. Не отправляй чувствительные данные. Ответы генерируются LLM.",
        "en": "I’m not a doctor. This is not medical care. Don’t send sensitive data. Answers are LLM-generated.",
        "es": "No soy médico. Esto no reemplaza atención médica. No envíes datos sensibles. Respuestas generadas por LLM.",
        "uk": "Я не лікар. Це не медична допомога. Не надсилай чутливі дані. Відповіді генерує LLM."
    },
    "intake": {
        "ru": (
            "Быстрый опрос (~40 сек). Ответь ОДНИМ сообщением, свободно:\n"
            "1) Возраст и пол.\n"
            "2) Главная цель (вес, энергия, сон, долголетие и т.п.).\n"
            "3) Основной симптом (если есть) и сколько длится.\n"
            "4) Хроника/операции/лекарства.\n"
            "5) Сон: во сколько ложишься/встаёшь.\n"
            "6) Активность: шаги/тренировки.\n"
            "7) Питание: как обычно ешь.\n"
            "8) Есть ли настораживающие признаки (сильная боль в груди, одышка, кровь, обморок и т.п.)?"
        ),
        "en": (
            "Quick intake (~40s). Reply in ONE message, free text:\n"
            "1) Age & sex.\n"
            "2) Main goal (weight, energy, sleep, longevity, etc.).\n"
            "3) Main symptom (if any) and duration.\n"
            "4) Conditions/surgeries/meds.\n"
            "5) Sleep: usual bed/wake time.\n"
            "6) Activity: steps/workouts.\n"
            "7) Diet: typical meals.\n"
            "8) Any red flags (severe chest pain, shortness of breath, blood, fainting, etc.)?"
        ),
        "es": (
            "Intake rápido (~40s). Responde en UN solo mensaje:\n"
            "1) Edad y sexo.\n"
            "2) Meta principal (peso, energía, sueño, longevidad, etc.).\n"
            "3) Síntoma principal (si hay) y duración.\n"
            "4) Condiciones/cirugías/medicamentos.\n"
            "5) Sueño: hora de dormir/levantarte.\n"
            "6) Actividad: pasos/entrenos.\n"
            "7) Dieta: comidas típicas.\n"
            "8) ¿Bandera roja (dolor fuerte en pecho, falta de aire, sangre, desmayo, etc.)?"
        ),
        "uk": (
            "Швидкий опитувальник (~40с). Відповідай ОДНИМ повідомленням:\n"
            "1) Вік і стать.\n"
            "2) Головна мета (вага, енергія, сон, довголіття тощо).\n"
            "3) Основний симптом (якщо є) і тривалість.\n"
            "4) Хроніка/операції/ліки.\n"
            "5) Сон: коли лягаєш/прокидаєшся.\n"
            "6) Активність: кроки/тренування.\n"
            "7) Харчування: що зазвичай їси.\n"
            "8) Червоні прапорці (сильний біль у грудях, задишка, кров, непритомність тощо)?"
        ),
    }
}

def tget(key: str, lang: str) -> str:
    return TXT.get(key, {}).get(lang) or TXT.get(key, {}).get("en", "")

# ---------- LLM prompts ----------
SYS_PARSER = """
Extract a user health profile from the text. Respond with MINIFIED JSON ONLY:
{"age":int|null,"sex":"male"|"female"|null,"goal":string|null,
 "main_symptom":string|null,"duration":string|null,
 "conditions":string[]|null,"surgeries":string[]|null,"meds":string[]|null,
 "sleep":{"bedtime":string|null,"waketime":string|null}|null,
 "activity":{"steps_per_day":int|null,"workouts":string|null}|null,
 "diet":string|null,"red_flags":bool|null,"language":"ru"|"en"|"es"|"uk"|null}
No prose.
"""

SYS_ROUTER = """
You are TendAI — a concise, professional health & longevity assistant (not a doctor).
BE COMPACT: <=6 short lines + up to 4 bullets. No fluff. No emojis.
TRIAGE RULES:
- Ask 1–2 targeted clarifying questions before advising ER, unless the user CLEARLY states a red-flag scenario (e.g., severe chest pain with shortness of breath, stroke signs, heavy bleeding). 
- If you advise ER, include a single-line rationale first, then the ER instruction.
OUTPUT STRICTLY MINIFIED JSON:
{"language":"ru"|"en"|"es"|"uk"|null,
 "intent":"symptom"|"nutrition"|"sleep"|"labs"|"habits"|"longevity"|"other",
 "slots":object,
 "severity":"low"|"moderate"|"high",
 "red_flags":boolean,
 "confidence":0..1,
 "assistant_reply":string,
 "followups":string[],    # <=2 short questions if needed
 "needs_more":boolean}
Style: clinical yet warm; science-informed; no diagnosis; offer practical next steps.
Use user's profile when helpful.
"""

def chat(model: str, messages: List[Dict[str, str]], temperature: float = 0.3, max_tokens: int = 500) -> str:
    resp = client.chat.completions.create(model=model, temperature=temperature, max_tokens=max_tokens, messages=messages)
    return resp.choices[0].message.content.strip()

def parse_profile(text: str, lang_hint: str) -> Dict[str, Any]:
    try:
        content = chat(OPENAI_MODEL, [
            {"role":"system","content":SYS_PARSER},
            {"role":"user","content":text}
        ], temperature=0.0, max_tokens=450)
        # ensure json only
        m = re.search(r"\{.*\}\s*$", content, re.S)
        if m: content = m.group(0)
        data = json.loads(content)
        if not data.get("language"):
            data["language"] = lang_hint
        return data
    except Exception as e:
        log.warning(f"parse_profile failed: {e}")
        # minimal fallback
        return {"age": None, "sex": None, "goal": None, "language": lang_hint}

def route_and_answer(user_text: str, lang: str, profile: Dict[str, Any], history: List[Dict[str,str]], fast: bool=False) -> Dict[str, Any]:
    sys = SYS_ROUTER + f"\nUser language hint: {lang}. Fast mode: {str(fast)}. Stored profile: {json.dumps(profile, ensure_ascii=False)}"
    content = chat(OPENAI_MODEL, [
        {"role":"system","content":sys},
        {"role":"user","content":user_text}
    ], temperature=0.2, max_tokens=480)
    try:
        m = re.search(r"\{.*\}\s*$", content, re.S)
        if m: content = m.group(0)
        data = json.loads(content)
        # Guard: soften premature ER advice
        if data.get("red_flags") and float(data.get("confidence", 0)) < 0.6:
            # flip to follow-up first
            data["red_flags"] = False
            data["assistant_reply"] = data.get("assistant_reply","")
            # ensure at least one follow-up
            if not data.get("followups"):
                data["followups"] = ["Please describe the location, character, and duration."]
            data["needs_more"] = True
        # Cap length defensively
        if isinstance(data.get("assistant_reply"), str):
            data["assistant_reply"] = data["assistant_reply"].strip()
        return data
    except Exception as e:
        log.warning(f"route_and_answer parse failed: {e}")
        # safe compact fallback
        fallback = {
            "ru":"Коротко: уточни где/какая боль и сколько длится. Базовые шаги: сон с фиксированным подъёмом, 7–10 тыс. шагов, овощи каждый приём, белок 1.2–1.6 г/кг/день.",
            "en":"Briefly: tell me where/what kind of pain and for how long. Basics: fixed wake, 7–10k steps, veggies each meal, protein 1.2–1.6 g/kg/day.",
            "es":"Breve: dónde/qué tipo de dolor y cuánto dura. Básicos: despertar fijo, 7–10k pasos, verduras cada comida, proteína 1.2–1.6 g/kg/día.",
            "uk":"Коротко: де/який біль і скільки триває. Базово: фіксоване пробудження, 7–10 тис. кроків, овочі кожний прийом, білок 1.2–1.6 г/кг/день."
        }.get(lang,"en")
        return {"language":lang,"intent":"other","slots":{},"severity":"low","red_flags":False,"confidence":0.3,
                "assistant_reply":fallback,"followups":["Що саме турбує зараз?"],"needs_more":True}

# ---------- Commands ----------
async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    st = USERS[update.effective_user.id]
    st.lang = detect_lang(update, st.lang)
    st.intake_needed = True
    st.history.clear()
    await update.effective_chat.send_message(tget("greet", st.lang), reply_markup=ReplyKeyboardRemove())
    await update.effective_chat.send_message(tget("privacy", st.lang))
    # IMMEDIATE INTAKE
    await update.effective_chat.send_message(TXT["intake"][st.lang])

async def cmd_reset(update: Update, context: ContextTypes.DEFAULT_TYPE):
    USERS[update.effective_user.id] = State()
    USERS[update.effective_user.id].lang = detect_lang(update, "en")
    await update.effective_chat.send_message("Reset. /start", reply_markup=ReplyKeyboardRemove())

async def cmd_privacy(update: Update, context: ContextTypes.DEFAULT_TYPE):
    st = USERS[update.effective_user.id]
    st.lang = st.lang or detect_lang(update, "en")
    await update.effective_chat.send_message(tget("privacy", st.lang), reply_markup=ReplyKeyboardRemove())

async def cmd_profile(update: Update, context: ContextTypes.DEFAULT_TYPE):
    st = USERS[update.effective_user.id]
    await update.effective_chat.send_message("Profile:\n" + json.dumps(st.profile or {}, ensure_ascii=False, indent=2))

async def cmd_plan(update: Update, context: ContextTypes.DEFAULT_TYPE):
    st = USERS[update.effective_user.id]
    sys = ("You are TendAI. Create a compact 4–6 step plan ONLY from this profile (no diagnosis). "
           "Use bullet points and short sentences.").strip()
    msgs = [{"role":"system","content":sys},
            {"role":"user","content":json.dumps(st.profile, ensure_ascii=False)}]
    try:
        reply = chat(OPENAI_MODEL, msgs, temperature=0.2, max_tokens=420)
    except Exception as e:
        log.warning(f"plan failed: {e}")
        reply = {"ru":"Не удалось сгенерировать план сейчас.",
                 "en":"Couldn’t generate a plan now.",
                 "es":"No se pudo generar el plan ahora.",
                 "uk":"Не вдалося створити план зараз."}.get(st.lang,"en")
    await update.effective_chat.send_message(reply)

async def cmd_fast(update: Update, context: ContextTypes.DEFAULT_TYPE):
    st = USERS[update.effective_user.id]
    st.fast_mode = True
    msg = {"ru":"Режим «быстро»: дай цель/симптом — отвечу сверхкоротко.",
           "en":"Fast mode: send goal/symptom — I’ll be ultra-brief.",
           "es":"Modo rápido: envía objetivo/síntoma — responderé muy breve.",
           "uk":"Швидкий режим: надішли мету/симптом — відповім дуже стисло."}.get(st.lang,"en")
    await update.effective_chat.send_message(msg)

# ---------- Message handler ----------
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    st = USERS[uid]
    st.lang = st.lang or detect_lang(update, "en")
    text = update.message.text or ""
    st.last_seen = now()

    # If we still need intake: parse profile first
    if st.intake_needed:
        prof = parse_profile(text, st.lang)
        st.profile.update({k:v for k,v in prof.items() if v not in [None, "", []]})
        st.intake_needed = False
        summary = json.dumps(st.profile, ensure_ascii=False, indent=2)
        confirm = {
            "ru":"Принял. Короткое резюме профиля:\n",
            "en":"Got it. Brief profile summary:\n",
            "es":"Entendido. Resumen del perfil:\n",
            "uk":"Прийнято. Короткий підсумок профілю:\n",
        }.get(st.lang,"en") + summary
        await update.effective_chat.send_message(confirm)
        # gentle next step
        nxt = {
            "ru":"С чего начнём прямо сейчас? (симптом/сон/питание/анализы/привычки/долголетие)",
            "en":"Where do you want to start now? (symptom/sleep/nutrition/labs/habits/longevity)",
            "es":"¿Por dónde empezamos ahora? (síntoma/sueño/nutrición/análisis/hábitos/longevidad)",
            "uk":"З чого почнемо зараз? (симптом/сон/харчування/аналізи/звички/довголіття)",
        }.get(st.lang,"en")
        await update.effective_chat.send_message(nxt)
        return

    # Normal dialog — route by LLM
    st.history.append({"role":"user","content": text})
    data = route_and_answer(text, st.lang, st.profile, list(st.history), fast=st.fast_mode)
    if isinstance(data.get("language"), str):
        st.lang = data["language"]

    reply = (data.get("assistant_reply") or "").strip()
    if not reply:
        reply = {"ru":"Сформулируй цель или вопрос одним предложением.",
                 "en":"Please state your goal or question in one sentence.",
                 "es":"Indica tu objetivo o pregunta en una frase.",
                 "uk":"Сформулюй мету або запитання одним реченням."}.get(st.lang,"en")

    st.history.append({"role":"assistant","content": reply})
    st.fast_mode = False  # one-shot

    await update.effective_chat.send_message(reply, reply_markup=ReplyKeyboardRemove())

    # Ask follow-ups if needed
    if data.get("needs_more") and data.get("followups"):
        for q in data["followups"][:2]:
            await update.effective_chat.send_message(q)

# ---------- Main ----------
def main():
    if TELEGRAM_TOKEN == "YOUR_TELEGRAM_TOKEN_HERE":
        log.warning("Set TELEGRAM_TOKEN")
    if OPENAI_API_KEY == "YOUR_OPENAI_API_KEY_HERE":
        log.warning("Set OPENAI_API_KEY")

    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("reset", cmd_reset))
    app.add_handler(CommandHandler("privacy", cmd_privacy))
    app.add_handler(CommandHandler("profile", cmd_profile))
    app.add_handler(CommandHandler("plan", cmd_plan))
    app.add_handler(CommandHandler("fast", cmd_fast))

    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

    log.info("TendAI (LLM-only) is running…")
    app.run_polling()

if __name__ == "__main__":
    main()
